{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0201eef8",
   "metadata": {
    "id": "0201eef8"
   },
   "source": [
    "# Linear regression [7 pts]\n",
    "\n",
    "In this homework, you will implement solution algorithms for linear regression.\n",
    "\n",
    "\n",
    "## Import libraries\n",
    "Let's begin by importing some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e93db53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e93db53",
    "outputId": "5317423b-9211-4f87-de3e-b3e4f51fcd91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f958f",
   "metadata": {
    "id": "3b7f958f"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Now, we are importing a dataset of diabetes. You can check the details on this dataset here: https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset.\n",
    "\n",
    "The dataset consists of 442 observations with 10 attributes ($X$) that may affect the progression of diabetes ($y$). Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of $n$ = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b7be6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45b7be6c",
    "outputId": "0a74823c-ebde-48fd-9a16-9d432ffdebae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input features: (442, 10)\n",
      "The shape of the output varaible: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "print('The shape of the input features:',diabetes_X.shape)\n",
    "print('The shape of the output varaible:',diabetes_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d43652",
   "metadata": {
    "id": "33d43652"
   },
   "source": [
    "We will choose just one attribute from the ten attributes as an input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333d01d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "333d01d6",
    "outputId": "53f93772-2ead-4b10-9eab-e93ca0918070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use only one feature\n",
    "diabetes_X_one = diabetes_X[:, np.newaxis, 2]\n",
    "print(diabetes_X_one.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d51ee",
   "metadata": {
    "id": "2d5d51ee"
   },
   "source": [
    "## Dataset split\n",
    "\n",
    "Now, we split the dataset into two parts: training set and test set.\n",
    "\n",
    "- training set: 422 samples\n",
    "- test set: 20 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1cadcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b1cadcc",
    "outputId": "1103e7e1-1c56-4916-f20c-36653137b407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input variable shape: (422, 1)\n",
      "Test input variable shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X_one[:-20]\n",
    "diabetes_X_test = diabetes_X_one[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "print('Training input variable shape:', diabetes_X_train.shape)\n",
    "print('Test input variable shape:', diabetes_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db6e06",
   "metadata": {
    "id": "69db6e06"
   },
   "source": [
    "## Linear regression\n",
    "\n",
    "Assume that we have a hypothesis $$ h_{\\theta}(x) = \\theta_0 + \\theta_1 x. $$\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "- [3pts] implement \\textbf{your own version} of the method of least-squares, compute and report $\\theta_0$ and $\\theta_1$ that minimize the residual sum of squares, )\n",
    "$$ \\sum_{i=1}^{N} \\frac{1}{2}( y^{(i)} - h_{\\theta}(x^{(i)})^2$$\n",
    "\n",
    "[IMPORTANT] Do not just call the least square function from libraries, for example,\n",
    "scipy.optimize.least_squares from scipy. Doing so will result in 0 point. Using helping functions such as numpy.linalg.inv is okay.\n",
    "\n",
    "- [3pts] implement your own version of the gradient descent algorithm, compute and report $\\theta_0$ and $\\theta_1$ that minimize the mean squared error $$ \\sum_{i=1}^{N} \\frac{1}{N}( y^{(i)} - h_{\\theta}(x^{(i)})^2$$\n",
    "\n",
    "[NOTE] Notice that the loss function is mean-squared error.\n",
    "\n",
    "- [1pts] derive the analytical expression of the gradient if the loss is defined as\n",
    "$$ \\sum_{i=1}^{N} \\frac{1}{2}( y^{(i)} - h_{\\theta}(x^{(i)})^2 + \\frac{\\lambda}{2} \\| \\theta \\|_2^2, $$\n",
    "where $\\theta = [\\theta_0, \\theta_1]^{\\intercal}$\n",
    "\n",
    "To check whether your computation is correct, consider using an API such as Scikit learn linearregression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GhGW2-m2hQ8w",
   "metadata": {
    "id": "GhGW2-m2hQ8w"
   },
   "source": [
    "# Method of least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "L2ZEi2Jz7jOl",
   "metadata": {
    "id": "L2ZEi2Jz7jOl"
   },
   "outputs": [],
   "source": [
    "x = diabetes_X_one\n",
    "y = np.array(diabetes_y)\n",
    "X_mat = [[] for _ in range(len(x))]\n",
    "for i in range(len(x)):\n",
    "   temp = np.array([1,x[i][0]])\n",
    "   X_mat[i] = temp\n",
    "X_mat = np.matrix(X_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "xM77tAf8_KK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xM77tAf8_KK9",
    "outputId": "ee44d105-3762-4173-e3c1-7e9102c7bdb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152.13348416 949.43526038]]\n"
     ]
    }
   ],
   "source": [
    "theta = np.linalg.inv(X_mat.T.dot(X_mat)).dot(X_mat.T).dot(y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tATCRO3iqJ0s",
   "metadata": {
    "id": "tATCRO3iqJ0s"
   },
   "source": [
    "## Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1IXQQys7HLcR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IXQQys7HLcR",
    "outputId": "acfa0db2-c770-4635-c6f0-5f19a344e53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01879682] [0.25738378]\n"
     ]
    }
   ],
   "source": [
    "theta0 = 0.0\n",
    "theta1 = 0.0\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "def gradient_desc(x, y, theta0, theta1, learning_rate):\n",
    "  dldtheta0 = 0.0\n",
    "  dldtheta1 = 0.0\n",
    "  N = x.shape[0]\n",
    "\n",
    "  for xi,yi in zip(x,y):\n",
    "    dldtheta0 = -2*xi*(yi-(theta1*xi+theta1))\n",
    "    dldtheta1 = -2*(yi-(theta1*xi+theta1))\n",
    "\n",
    "  theta0 = theta0 - learning_rate*(1/N)*dldtheta0\n",
    "  theta1 = theta1 - learning_rate*(1/N)*dldtheta1\n",
    "  return theta0,theta1\n",
    "\n",
    "for epoch in range(100):\n",
    "  theta0, theta1 = gradient_desc(x,y,theta0,theta1, learning_rate)\n",
    "  yhat = theta0*x + theta1\n",
    "  loss = np.divide(np.sum((y-yhat)**2, axis = 0),x.shape[0])\n",
    "\n",
    "print(theta0, theta1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
